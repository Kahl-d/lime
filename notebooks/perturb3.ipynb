{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/923673423/.local/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /Users/923673423/.local/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in /Users/923673423/.local/lib/python3.9/site-packages (4.47.0)\n",
      "Requirement already satisfied: datasets in /Users/923673423/.local/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.22.4; python_version < \"3.11\" in /Users/923673423/.local/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/923673423/.local/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/923673423/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/923673423/.local/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1; python_version >= \"3.9\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: jinja2 in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: networkx in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /Users/923673423/.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: requests in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/923673423/.local/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/923673423/.local/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /Users/923673423/.local/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/923673423/.local/lib/python3.9/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /Users/923673423/.local/lib/python3.9/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/923673423/.local/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/923673423/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/923673423/.local/lib/python3.9/site-packages (from sympy==1.13.1; python_version >= \"3.9\"->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/923673423/.local/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/923673423/.local/lib/python3.9/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/923673423/.local/lib/python3.9/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/923673423/.local/lib/python3.9/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/923673423/.local/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/923673423/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas torch transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/923673423/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"/Users/923673423/lime/fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/923673423/lime/data/data_class.csv')\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'Unnamed: 0': 'Index',\n",
    "    'SEQN': 'Sequence Number',\n",
    "    'RIAGENDR': 'Gender',\n",
    "    'RIDAGEYR': 'Age',\n",
    "    'DMDHHSIZ': 'Household Size',\n",
    "    'INDFMPIR': 'Income Poverty Ratio',\n",
    "    'BMXBMI': 'Body Mass Index',\n",
    "    'DSD010': 'Diet Question One',\n",
    "    'DSD010AN': 'Diet Question Alternate',\n",
    "    'SMD415': 'Smoking Status',\n",
    "    'PAD590': 'Physical Activity One',\n",
    "    'PAD600': 'Physical Activity Two',\n",
    "    'HUQ010': 'Health Status',\n",
    "    'restaurant': 'Restaurant Visits',\n",
    "    'protein': 'Protein Intake',\n",
    "    'healthy': 'Healthy Food Intake',\n",
    "    'unhealthy': 'Unhealthy Food Intake',\n",
    "    'beverage': 'Beverage Consumption',\n",
    "    'milk': 'Milk Consumption',\n",
    "    'MCQ010': 'Medical Condition One',\n",
    "    'MCQ053': 'Medical Condition Two',\n",
    "    'MCQ092': 'Medical Condition Three',\n",
    "    'MCQ140': 'Medical Condition Four',\n",
    "    'active': 'Physical Activity Status'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_descriptions(data):\n",
    "    \"\"\"\n",
    "    Generate detailed text descriptions for each row in the dataset.\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        try:\n",
    "            description = (\n",
    "                f\"The individual is {'male' if row['Gender'] == 1 else 'female'} and is {row['Age']} years old. \"\n",
    "                f\"They live in a household with {row['Household Size']} members. Their income-to-poverty ratio is {row['Income Poverty Ratio']:.2f}, \"\n",
    "                f\"which is {'below average' if row['Income Poverty Ratio'] < 1 else 'moderate' if 1 <= row['Income Poverty Ratio'] <= 3 else 'above average'}. \"\n",
    "                f\"Their body mass index (BMI) is {row['Body Mass Index']:.1f}, calculated from their weight and height. \"\n",
    "                f\"This indicates they are {'underweight' if row['Body Mass Index'] < 18.5 else 'in the normal range' if 18.5 <= row['Body Mass Index'] < 25 else 'overweight' if 25 <= row['Body Mass Index'] < 30 else 'obese'}. \"\n",
    "                f\"They answered '{row['Diet Question One']}' to a dietary question and '{row['Diet Question Alternate']}' as an alternate response. \"\n",
    "                f\"They currently {'do not smoke' if row['Smoking Status'] == 'No' else 'are smokers'}. \"\n",
    "                f\"Their physical activity includes {row['Physical Activity One']} minutes of moderate activity and {row['Physical Activity Two']} minutes of vigorous activity weekly. \"\n",
    "                f\"Their self-reported health status is {row['Health Status']} out of 5. \"\n",
    "                f\"They visit restaurants {row['Restaurant Visits']} times monthly and consume {row['Protein Intake']} grams of protein daily. \"\n",
    "                f\"Medical conditions include: One={row['Medical Condition One']}, Two={row['Medical Condition Two']}, \"\n",
    "                f\"Three={row['Medical Condition Three']}, Four={row['Medical Condition Four']}. \"\n",
    "                f\"Their overall physical activity status is {row['Physical Activity Status']}.\"\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing column in data: {e}\")\n",
    "            description = \"Incomplete data.\"\n",
    "        descriptions.append(description)\n",
    "\n",
    "    return pd.Series(descriptions)\n",
    "\n",
    "\n",
    "data['Text_Description'] = generate_text_descriptions(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(description, top_n=5):\n",
    "    \"\"\"\n",
    "    Predict masked values in the description using the model.\n",
    "\n",
    "    Args:\n",
    "        description (str): The input description with masked values.\n",
    "        top_n (int): Number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        list: Predicted values for each mask.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(description, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits\n",
    "\n",
    "    mask_token_indices = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "    all_predicted_values = []\n",
    "\n",
    "    for mask_idx in mask_token_indices:\n",
    "        # Handle top_k properly to avoid issues with single predictions\n",
    "        try:\n",
    "            predicted_token_ids = predictions[0, mask_idx].topk(top_n).indices.squeeze().tolist()\n",
    "        except ValueError:\n",
    "            predicted_token_ids = [predictions[0, mask_idx].topk(1).indices.item()]  # Default to single prediction\n",
    "\n",
    "        predicted_tokens = [tokenizer.decode(token_id).strip() for token_id in predicted_token_ids]\n",
    "        all_predicted_values.append(predicted_tokens)\n",
    "\n",
    "    return all_predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description_with_mask(row, mask_token=\"[MASK]\", columns_to_mask=None):\n",
    "    \"\"\"\n",
    "    Generate a description for a row with specified columns masked.\n",
    "    \"\"\"\n",
    "    description = generate_text_descriptions(pd.DataFrame([row])).iloc[0]\n",
    "    for col in columns_to_mask:\n",
    "        if col in row:\n",
    "            description = description.replace(str(row[col]), mask_token)\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m single_row \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Generate perturbed dataset for the single row\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m perturbed_dataset_dynamic \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_highly_dynamic_perturbations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_mask_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Display or save the perturbed dataset\u001b[39;00m\n\u001b[1;32m     88\u001b[0m perturbed_dataset_dynamic\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[32], line 25\u001b[0m, in \u001b[0;36mgenerate_highly_dynamic_perturbations\u001b[0;34m(row, numeric_columns, categorical_columns, num_samples, max_mask_columns)\u001b[0m\n\u001b[1;32m     23\u001b[0m masked_description \u001b[38;5;241m=\u001b[39m generate_description_with_mask(row, columns_to_mask\u001b[38;5;241m=\u001b[39mcolumns_to_mask)\n\u001b[1;32m     24\u001b[0m top_n_predictions \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Randomize top-n predictions for more variety\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mextract_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_n_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predicted_combination \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mpredictions):\n\u001b[1;32m     28\u001b[0m     perturbed_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[31], line 27\u001b[0m, in \u001b[0;36mextract_predictions\u001b[0;34m(description, top_n)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         predicted_token_ids \u001b[38;5;241m=\u001b[39m [predictions[\u001b[38;5;241m0\u001b[39m, mask_idx]\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mitem()]  \u001b[38;5;66;03m# Default to single prediction\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     predicted_tokens \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_id)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m token_id \u001b[38;5;129;01min\u001b[39;00m predicted_token_ids]\n\u001b[1;32m     28\u001b[0m     all_predicted_values\u001b[38;5;241m.\u001b[39mappend(predicted_tokens)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_predicted_values\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def generate_highly_dynamic_perturbations(row, numeric_columns, categorical_columns, num_samples=50, max_mask_columns=3):\n",
    "    \"\"\"\n",
    "    Generate a highly dynamic and diverse set of perturbations for a single row.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A single row of the dataset.\n",
    "        numeric_columns (list): List of numeric columns to perturb.\n",
    "        categorical_columns (list): List of categorical columns to perturb.\n",
    "        num_samples (int): Number of perturbations to generate.\n",
    "        max_mask_columns (int): Maximum number of columns to mask in a single perturbation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset with highly dynamic and diverse perturbed rows.\n",
    "    \"\"\"\n",
    "    perturbed_data = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select 1 to `max_mask_columns` columns to mask\n",
    "        num_columns_to_mask = random.randint(1, max_mask_columns)\n",
    "        columns_to_mask = random.sample(list(row.index), num_columns_to_mask)\n",
    "\n",
    "        # Mask the selected columns\n",
    "        masked_description = generate_description_with_mask(row, columns_to_mask=columns_to_mask)\n",
    "        top_n_predictions = random.randint(1, 5)  # Randomize top-n predictions for more variety\n",
    "        predictions = extract_predictions(masked_description, top_n=top_n_predictions)\n",
    "\n",
    "        for predicted_combination in zip(*predictions):\n",
    "            perturbed_row = row.copy()\n",
    "\n",
    "            # Apply predictions directly to masked columns\n",
    "            for col, value in zip(columns_to_mask, predicted_combination):\n",
    "                if col in numeric_columns:\n",
    "                    perturbed_row[col] = try_convert_to_numeric(value, default=row[col]) + random.uniform(-5, 5)\n",
    "                elif col in categorical_columns:\n",
    "                    perturbed_row[col] = value\n",
    "\n",
    "            # Randomly tweak unmasked numeric columns to add slight variability\n",
    "            for col in numeric_columns:\n",
    "                if col not in columns_to_mask:\n",
    "                    perturbed_row[col] += random.uniform(-2, 2)\n",
    "\n",
    "            perturbed_data.append(perturbed_row)\n",
    "\n",
    "    return pd.DataFrame(perturbed_data)\n",
    "\n",
    "\n",
    "def try_convert_to_numeric(value, default):\n",
    "    \"\"\"\n",
    "    Try to convert a value to numeric. If conversion fails, return the default value.\n",
    "\n",
    "    Args:\n",
    "        value (str): The value to convert.\n",
    "        default: The default value to return if conversion fails.\n",
    "\n",
    "    Returns:\n",
    "        float or int: The converted value or the default.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "numeric_columns = [\n",
    "    'Age', 'Household Size', 'Body Mass Index', 'Physical Activity One',\n",
    "    'Physical Activity Two', 'Protein Intake', 'Healthy Food Intake', 'Unhealthy Food Intake'\n",
    "]\n",
    "categorical_columns = [\n",
    "    'Gender', 'Smoking Status', 'Health Status', 'Diet Question One', 'Diet Question Alternate',\n",
    "    'Medical Condition One', 'Medical Condition Two', 'Medical Condition Three', 'Medical Condition Four',\n",
    "    'Physical Activity Status'\n",
    "]\n",
    "\n",
    "# Select a single row\n",
    "single_row = data.iloc[0]\n",
    "\n",
    "# Generate perturbed dataset for the single row\n",
    "perturbed_dataset_dynamic = generate_highly_dynamic_perturbations(\n",
    "    row=single_row,\n",
    "    numeric_columns=numeric_columns,\n",
    "    categorical_columns=categorical_columns,\n",
    "    num_samples=50,\n",
    "    max_mask_columns=3\n",
    ")\n",
    "\n",
    "# Display or save the perturbed dataset\n",
    "perturbed_dataset_dynamic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
